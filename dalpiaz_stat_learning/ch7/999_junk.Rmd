---
title: skeleton.qmd
date: last-modified
# Quarto requires title, if want date to appear
TAGS:  caret, knn3, 
---
### https://statisticallearning.org/nonparametric-classification.html
  ### Dalpiaz - Chapter 7 (generate data, from Chapter 7)
```{r}
library(mlbench)
library(palmerpenguins)
library(tidyverse)
library(gridExtra)
library(caret)
```

### generate training/testing data
```{r}
# set seed
set.seed(42)

# generate data 1000 rows, 2 cols, 3 classes 
sim_data = as_tibble(mlbench.2dnormals(n = 1000, cl = 3, sd = 1.3))
head(sim_data)

# train-test | tst-trn split data
trn_idx = sample(nrow(sim_data), size = 0.8 * nrow(sim_data))
length(trn_idx)                        #800 
trn = sim_data[trn_idx, ]
tst = sim_data[-trn_idx, ]

# est-val split data
est_idx = sample(nrow(trn), size = 0.8 * nrow(trn))
length(est_idx)                        #640 
est = trn[est_idx, ]                   #640 x 3 
val = trn[-est_idx, ]                  #160 x 3 

# check data
trn
trn |> dim() 
```

```{r}
# visualize data

p1 = ggplot(data = trn, aes(x = x.1)) +
  geom_density(aes(fill = classes), alpha = 0.5) +
  scale_fill_manual(values=c("grey", 2, 3))

p2 = ggplot(data = trn, aes(x = x.2)) +
  geom_density(aes(fill = classes), alpha = 0.5) +
  scale_fill_manual(values=c("grey", 2, 3))

p3 = ggplot(data = trn, aes(x = x.1)) +
  geom_histogram(aes(fill = classes), alpha = 0.7, position = "identity") +
  scale_fill_manual(values=c("grey", 2, 3))

p4 = ggplot(data = trn, aes(x = x.2)) +
  geom_histogram(aes(fill = classes), alpha = 0.7, position = "identity") +
  scale_fill_manual(values=c("grey", 2, 3))

gridExtra::grid.arrange(p1, p2, p3, p4)
```

#
```{r}
# fit knn model
mod_knn = knn3(classes ~ ., data = trn, k = 10)

# make "predictions" with knn model
new_obs = data.frame(x.1 = 2, x.2 = -2)

# point is probably class 3
predict(mod_knn, new_obs, type = "prob")
predict(mod_knn, new_obs, type = "class")

```
### Next:  more knn, or begin tree model
### plot
```{r}
plot(x.2 ~ x.1, data = trn, col = classes, pch = 20, cex = 1.5)
# grid()
```


### helper function to calculate misclassification
```{r}
calc_misclass = function(actual, predicted) {
  mean(actual != predicted)
}

# calculate test metric
mod_knn = knn3(classes ~ ., data = trn, k = 10)
calc_misclass(
  actual = tst$classes,
  predicted = predict(mod_knn, tst, type = "class")
)
```

### simulate
```{r}
library(caret)
# tune knn model ###############################################################

# set seed
set.seed(42)

# est data (3 clusters, lots of overlap)
plot(x.2 ~ x.1, data = est, col = classes, pch = 20, cex = 1.5)

# k values to consider
k_val = seq(1, 101, by = 2)

# function to fit knn to est for various k

fit_knn_to_est = function(k) {
  knn3(classes ~ ., data = est, k = k)
}

# fit models
knn_mods = lapply(k_val, fit_knn_to_est)

# make predictions
knn_preds = lapply(knn_mods, predict, val, type = "class")

# calculate validation misclass
knn_misclass = sapply(knn_preds, calc_misclass, actual = val$classes)
min(knn_misclass)
which(knn_misclass == 0.244)
which(knn_misclass[min(knn_misclass)])

# plot results
plot(k_val, knn_misclass, pch = 20, type = "b")
grid()
```




vim:linebreak:nospell:nowrap:cul tw=78 fo=tqlnrc foldcolumn=1 cc=+1
